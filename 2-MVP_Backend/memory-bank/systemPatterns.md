# System Patterns: NLP-Atomic-Backend

## System Architecture
The NLP-Atomic-Backend is a stateless API service built with Python and Flask (or FastAPI). It follows a modular design, separating concerns into distinct components for API handling, Natural Language Processing, command validation, and command execution.

```mermaid
graph TD
    Client[Frontend Application] -->|POST /api/commands (JSON: {prompt: "..."})| API[API Layer (app.py)]

    subgraph NLP-Atomic-Backend
        API -->|User Prompt| NLPClient[NLP Client (nlp/llm_client.py)]
        NLPClient -->|Prompt, Function Schemas, Few-shot Examples| OpenAI[OpenAI ChatCompletion API]
        OpenAI -->|JSON Command Sequence| NLPClient
        NLPClient -->|Raw JSON Commands| Validator[Validation Module (models/commands.py)]
        Validator -->|Validated Command Objects| Executor[Executor Module]
        Executor -->|Executes buildStructure| StructureExecutor[Structure Executor (executor/structure.py)]
        StructureExecutor -->|Uses ASE| ASE[ASE Library]
        Executor -->|Executes setView, rotateCamera| ViewExecutor[View Executor (executor/view.py)]
        
        StructureExecutor -->|PDB/XYZ Text| Executor
        ViewExecutor -->|View Object| Executor
        Executor -->|Aggregated Results| API
    end

    API -->|JSON: [{command: "...", params: {...}, result: ...}]| Client
```

## Key Technical Decisions
- **Stateless API:** No user sessions or persistent data are managed by the backend. All necessary context for a request is contained within the request itself, and all results are returned in the response. This simplifies scaling and improves reliability.
- **LLM Function Calling:** Leverages OpenAI's function calling capability to guide the LLM into producing structured JSON commands that match predefined schemas. This is more reliable than simple prompt engineering for structured output.
- **Pydantic for Validation:** Uses Pydantic models to define and enforce the schema for all commands and their parameters. This ensures data integrity and provides clear error messages for invalid inputs.
- **Modular Executor:** Separates the logic for executing different types of commands (e.g., structure generation, view manipulation) into distinct executor modules. This promotes separation of concerns and makes the system easier to extend.
- **Raw Data Return (V1):** For `buildStructure` commands, the backend returns the raw PDB or XYZ text content directly in the JSON response. This avoids the need for the backend to host files in V1, simplifying deployment.
- **Flask (or FastAPI):** A lightweight Python web framework suitable for building APIs. FastAPI might be chosen for its built-in data validation and async capabilities if future needs arise.

## Design Patterns in Use
- **API Gateway:** `app.py` acts as the single entry point for all client requests.
- **Client-Server:** Standard model where the frontend is the client and this service is the server.
- **Modular Design:** Code is organized into modules with specific responsibilities (API, NLP, Validation, Execution).
- **Strategy Pattern (Implicit):** The `Executor` module could be seen as implicitly using a strategy pattern, where different command types are handled by different "strategy" functions (e.g., `build_structure`, `compute_set_view`).
- **Data Transfer Objects (DTOs):** Pydantic models serve as DTOs for commands and their parameters, ensuring consistent data structures throughout the system.

## Component Relationships
- **`app.py` (API Layer):**
    - Receives HTTP POST requests at `/api/commands`.
    - Parses the incoming JSON request to get the user's prompt.
    - Orchestrates the call sequence: NLP Client → Validation Module → Executor Module.
    - Formats the final list of executed commands and their results into a JSON response.
    - Handles global error wrapping.
- **`nlp/llm_client.py` (NLP Client):**
    - Takes a user prompt string.
    - Constructs the messages array with system prompt, few-shot examples, and the user prompt.
    - Defines the function schemas for `buildStructure`, `setView`, `rotateCamera`, etc.
    - Calls the OpenAI ChatCompletion API with function calling enabled.
    - Extracts and returns the list of JSON command objects generated by the LLM.
- **`models/commands.py` (Validation Module):**
    - Defines Pydantic models for each command type (e.g., `BuildStructureParams`, `RotateCameraParams`) and a main `Command` model (likely a Pydantic `Union` type).
    - Provides a `validate_commands` function that takes the raw list of JSON commands from the NLP client and parses/validates them into a list of Pydantic `Command` objects.
- **`executor/structure.py` (Structure Executor):**
    - Contains `build_structure(params: BuildStructureParams)` function.
    - Uses the ASE library to generate a crystal structure based on `params.element`, `params.lattice`, `params.nx`, `params.ny`, `params.nz`.
    - Writes the structure to an in-memory buffer (e.g., `io.StringIO`) as PDB or XYZ format.
    - Returns the string content of the structure file.
- **`executor/view.py` (View Executor):**
    - Contains functions like `compute_set_view(params: SetViewParams)` and `compute_rotate_camera(params: RotateCameraParams, prev_view_object: dict)`.
    - Calculates and returns a `viewObject` dictionary compatible with 3Dmol.js.
- **`utils/` (Utilities):**
    - May contain helper functions for file/text manipulation, custom error classes, logging configuration.

## Critical Implementation Paths
1.  **Prompt → LLM → Validated Commands:** Ensuring the LLM consistently generates commands that pass Pydantic validation. This relies on well-crafted system prompts, few-shot examples, and accurate function schemas.
2.  **Command Execution & Result Aggregation:** Correctly dispatching validated commands to their respective executor functions and assembling their results into the final JSON response array.
3.  **Error Handling:** Implementing robust error handling at each stage (NLP, validation, execution) and mapping internal errors to appropriate HTTP status codes and user-friendly error messages in the API response.
4.  **Performance:** The entire request-response cycle, including LLM interaction and ASE generation, must complete within the 3-second target.